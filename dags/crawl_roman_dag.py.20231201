"""
å–å¾—ä½¿ç”¨è€…çš„é–±è®€æ¸…å–®
å»ç¶²é å–å¾—æœ€æ–°ä¸€è©±è³‡è¨Š
è·Ÿä½¿ç”¨è€…é–±è®€ç´€éŒ„æ¯”è¼ƒæœ‰æ²’æœ‰æ›´æ–°é€£è¼‰
Ja,
    ç”Ÿæˆé€šçŸ¥è¨Šæ¯
    é€šçŸ¥ä½¿ç”¨è€…
    æ›´æ–°ä½¿ç”¨è€…é–±è®€ç´€éŒ„
Nein,
    Nicht tun
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.operators.branch import BaseBranchOperator
from airflow.models.taskinstance import TaskInstance
from datetime import datetime
import json
import os
import re


def process_read_history(mode, ti: TaskInstance):
    """è®€å–æˆ–æ›´æ–°é–±è®€ç´€éŒ„"""

    read_history_path = os.path.join("airflow/data/read_history.json")
    if mode == "read":
        with open(read_history_path, "r", encoding="utf-8") as fp:
            read_history = json.load(fp)
        # read_history = dict(read_history)
        # bookids = read_history.keys()
        # ti.xcom_push(key="bookids", value=bookids)
        return dict(read_history)
    elif mode == "update":
        print("æ›´æ–°")
    else:
        print("éŒ¯èª¤")


def check_updated_and_generate_message(ti: TaskInstance):
    read_history = ti.xcom_pull(task_ids="get_read_history")
    with open("../data/crawl.jsonl", "r", encoding="utf-8") as fp:
        crawl_roman_list = [
            json.loads(crawl_roman_json) for crawl_roman_json in fp.readlines()
        ]

    notification_messages = []
    updated = False
    for crawl_roman_json in crawl_roman_list:
        crawl_roman = dict(crawl_roman_json).items()
        bookid = crawl_roman["bookid"]
        latest_episode_info = crawl_roman["latest_episode_info"]
        latest_chapter_num = latest_episode_info["text"].split(" ")[0]
        previous_chapter_num = read_history[bookid]["previous_chapter_num"]

        updated = latest_chapter_num != previous_chapter_num or updated
        # updated = any((updated, latest_chapter_num != previous_chapter_num))
        # updated = True if latest_chapter_num != previous_chapter_num else updated

        title = latest_episode_info["title"]
        href = f'https://tw.mingzw.net{latest_episode_info["href"]}'
        try:
            # å°èªªå:ä¸–å®¶æ—å¥³ ä½œè€…:å¤œçº–é›ª ç« ç¯€å:ç¬¬ä¸‰åä¸ƒç«  æ”¶ç•™ æ›´æ–°æ™‚é–“:11-29
            pattern = re.compile(
                r"å°èªªå:(?P<bookname>.*?) ä½œè€…:(?P<author>.*?) ç« ç¯€å:(?P<episode_name>.*?) æ›´æ–°æ™‚é–“:(?P<update_date>.*?)$"
            )
            match = pattern.search(title)
            data = match.groupdict()
            data = {key: value.strip() for key, value in data.items()}
            message = f"ğŸ˜{data['update_date']} {data['bookname']} {data['episode_name']} {data['author']} {href}"
        except Exception as e:
            print(e)
            message = f"ğŸ™„{title} {href}"

        notification_messages.append(message)

    with open("../data/message.txt", "w", encoding="utf-8") as fp:
        fp.writelines(notification_messages)

    return updated


dag = DAG(
    dag_id="crawl_roman_dag",
    start_date=datetime(2023, 11, 29),
    schedule=None,
    catchup=False,
)

get_read_history = PythonOperator(
    task_id="get_read_history",
    python_callable=process_read_history,
    op_args=["read"],
    dag=dag,
)

# cd ~/airflow/crawl_roman;scrapy runspider crawl_roman/spiders/mingzw.py -a bookids=39680,38692
get_roman_info = BashOperator(
    task_id="get_roman_info",
    bash_command="cd ~/airflow/crawl_roman;scrapy crawl mingzw -a bookids=\"{{','.join(ti.xcom_pull('get_read_history').keys())}}\"",
    dag=dag,
)

check_roman_updated = PythonOperator(
    task_id="check_roman_updated",
    python_callable=check_updated_and_generate_message,
    dag=dag,
)

get_read_history >> get_roman_info

# @task
# def check_roman_updated(process):
#     return

# @task
# def send_notification():
#     return

# @task
# def update_read_history():
#     return process_read_history("update")

# @task
# def roman_not_updated():
#     return
